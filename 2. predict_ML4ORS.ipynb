{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score \n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "import random\n",
    "\n",
    "import shap\n",
    "import joblib\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Load the dataset\n",
    "# We assume that the dataset is in EXCEL format\n",
    "file_path = 'CLEANED_FILE_INPUT.xlsx'  # Enter the file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = 16\n",
    "output_dir = 'DIRECTORY/'+str(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting time variables to datetime format\n",
    "# Change to handle 'DD/MM/YYYY HH:MM' format\n",
    "df['INGRESSOSALA'] = pd.to_datetime(df['INGRESSOSALA'], format='%d/%m/%Y %H:%M')\n",
    "df['USCITASALA'] = pd.to_datetime(df['USCITASALA'], format='%d/%m/%Y %H:%M')\n",
    "\n",
    "# Creating 'DURATION' column (in minutes)\n",
    "df['DURATA'] = (df['USCITASALA'] - df['INGRESSOSALA']).dt.total_seconds() / 60\n",
    "\n",
    "# Remove lines with negative duration (any errors)\n",
    "df = df[df['DURATA'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DURATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Null Analysis\n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "# Remove columns with more than 50% missing values\n",
    "threshold = 0.5\n",
    "df = df[df.columns[df.isnull().mean() < threshold]]\n",
    "\n",
    "# Check for no more null values\n",
    "df = df.dropna(how='any',axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Seaborn to plot the point distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(df['DURATA'], kde=True, bins=10, color='skyblue')\n",
    "\n",
    "# Set titles\n",
    "plt.title('Distribution of Points')\n",
    "plt.xlabel('Duration')\n",
    "plt.ylabel('Items')\n",
    "\n",
    "# Show graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of durations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df['DURATA'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of the duration of the interventions', fontsize=16)\n",
    "plt.xlabel('Duration (minutes)', fontsize=14)\n",
    "plt.ylabel('Frequence', fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of durations\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(df['DURATA'], vert=False, patch_artist=True, \n",
    "            boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "            whiskerprops=dict(color='blue'), capprops=dict(color='blue'),\n",
    "            medianprops=dict(color='red'))\n",
    "plt.title('Boxplot of the duration of the interventions', fontsize=16)\n",
    "plt.xlabel('Duration (minutes)', fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display remaining columns in dataset\n",
    "print(\"Remaining columns in dataset:\")\n",
    "print(df.columns)\n",
    "X = df\n",
    "X = X.drop(columns=X.select_dtypes(include='datetime64[ns]').columns)\n",
    "print(X.dtypes)\n",
    "\n",
    "progressivo = df['PROGRESSIVO']  # Keep column name\n",
    "rep = df['REPARTO']  # Keep column name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_high_corr_features_with_categoricals(df, threshold=0.95):\n",
    "    df = df.copy()\n",
    "    cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "    num_cols = df.select_dtypes(exclude=['object', 'category']).columns\n",
    "\n",
    "    # Encode categorical features\n",
    "    encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "    df[cat_cols] = encoder.fit_transform(df[cat_cols])\n",
    "\n",
    "    # Compute correlation matrix (absolute values)\n",
    "    corr_matrix = df.corr().abs()\n",
    "\n",
    "    # Create a boolean mask to ignore the upper triangle (it's symmetric)\n",
    "    upper = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    upper_matrix = corr_matrix.where(upper)\n",
    "\n",
    "    # Find columns with correlation > threshold\n",
    "    to_drop = [column for column in upper_matrix.columns if any(upper_matrix[column] > threshold)]\n",
    "\n",
    "    # Drop them from the dataframe\n",
    "    df_filtered = df.drop(columns=to_drop)\n",
    "\n",
    "    return df_filtered, to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned, removed = remove_high_corr_features_with_categoricals(df.drop(columns=['DURATA']))\n",
    "print(\"Removed features due to high correlation:\", removed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 'DURATA' represents target variable\n",
    "y = df['DURATA']\n",
    "X.drop(columns=['DURATA'], inplace=True)\n",
    "X = df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#experiment ID\n",
    "exp = 15\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=10, random_state=SEED)\n",
    "gb = GradientBoostingRegressor(n_estimators=400, learning_rate=0.01, max_depth=15, random_state=SEED)\n",
    "dt = DecisionTreeRegressor(criterion='friedman_mse', max_depth=50, min_samples_split=2, random_state=SEED)\n",
    "xgboost = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=400, learning_rate=0.1, max_depth=5,\n",
    "                           tree_method=\"hist\", eval_metric='mae', random_state=SEED)\n",
    "svr = SVR()\n",
    "knn = KNeighborsRegressor(n_neighbors=5, weights='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [2, 5, 10],\n",
    "        'max_depth': [ 2, 4, None],\n",
    "         'min_samples_split': [2, 5]\n",
    "    },\n",
    "    'Gradient Boosting': {\n",
    "        'n_estimators': [50, 100, 200, 400],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [15, 30],\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [50, 100],\n",
    "        'min_samples_split': [1, 2],\n",
    "        'criterion': ['friedman_mse']\n",
    "    },\n",
    "    'Support Vector Regressor': {\n",
    "        'C': [0.1, 1],\n",
    "        'epsilon': [0.01, 0.1],\n",
    "        'kernel': ['rbf', 'linear']\n",
    "    },\n",
    "    'K-Nearest Neighbors': {\n",
    "        'n_neighbors': [3, 4, 5, 32],\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'xgboost': {\n",
    "        'n_estimators': [200, 400, 600],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [2, 5]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "# Split data into training and test sets while keeping PROGRESSIVO\n",
    "num_bins = 170  # You can adjust this\n",
    "y_binned = pd.qcut(y, q=num_bins, labels=False, duplicates='drop')\n",
    "\n",
    "# Use the binned variable for stratification\n",
    "X_train, X_test, y_train, y_test, prog_train, prog_test, rep_train, rep_test = train_test_split(\n",
    "    X, y, progressivo, rep,\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=y_binned\n",
    ")\n",
    "\n",
    "# Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to DataFrame and re-associate the PROGRESSIVE column in the test set\n",
    "X_test_df = pd.DataFrame(X_test_scaled)\n",
    "X_test_df['PROGRESSIVO'] = prog_test.values  # Let's re-associate PROGRESSIVO\n",
    "X_test_df['REPARTO'] = rep_test.values  # Let's re-associate PROGRESSIVO\n",
    "\n",
    "y_test_df = pd.DataFrame(y_test)\n",
    "y_test_df['PROGRESSIVO'] = prog_test.values  # Let's re-associate PROGRESSIVO\n",
    "y_test_df['REPARTO'] = rep_test.values  # Let's re-associate REPARTO\n",
    "\n",
    "# Convert to DataFrame and re-associate the PROGRESSIVE column in the train set\n",
    "X_train_df = pd.DataFrame(X_train_scaled)\n",
    "X_train_df['PROGRESSIVO'] = prog_train.values  # Let's re-associate PROGRESSIVO\n",
    "X_train_df['REPARTO'] = rep_train.values  # Let's re-associate REPARTO\n",
    "\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df['PROGRESSIVO'] = prog_train.values  # Let's re-associate PROGRESSIVO\n",
    "y_train_df['REPARTO'] = rep_train.values  # Let's re-associate REPARTO\n",
    "\n",
    "# List of models \n",
    "models = {\n",
    "    'Random Forest': rf,\n",
    "    'Gradient Boosting': gb,\n",
    "    'Decision Tree': dt,\n",
    "    'Support Vector Regressor': svr,\n",
    "    'K-Nearest Neighbors': knn,\n",
    "    'xgboost': xgboost\n",
    "\n",
    "}\n",
    "\n",
    "# Prepare data for the DataFrame\n",
    "data = []\n",
    "for name, model in models.items():\n",
    "    params = model.get_params()\n",
    "    for param, value in params.items():\n",
    "        data.append({\n",
    "            'Model': name,\n",
    "            'Parameter': param,\n",
    "            'Value': value\n",
    "        })\n",
    "\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Create and save the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(output_dir+'/configurations.csv', index=False)\n",
    "\n",
    "\n",
    "best_models = {}\n",
    "preds = {}\n",
    "mae_results, rmse_results, r2_results = {}, {}, {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} with GridSearchCV...\")\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grids[name],\n",
    "        cv=5,  # CV is only on training set\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Fit only on training data\n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_models[name] = best_model\n",
    "\n",
    "    # Predict on the untouched test set\n",
    "    y_pred = best_model.predict(X_test_scaled)\n",
    "    preds[name] = y_pred\n",
    "\n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    mae_results[name] = mae\n",
    "    rmse_results[name] = rmse\n",
    "    r2_results[name] = r2\n",
    "\n",
    "    # Print results\n",
    "    print(f\"{name} - Best Params: {grid_search.best_params_}\")\n",
    "    print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}\")\n",
    "\n",
    "    # Save model\n",
    "    joblib.dump(best_model, f'../models/no_out/{exp}/model_durata_intervento_{name}_best.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pred_y = pd.merge(y_test_df['PROGRESSIVO'], pd.DataFrame(y_pred, columns=['LABEL']), left_index=True, right_index=True)\n",
    "merged_pred_y_2 = pd.merge(y_test_df['REPARTO'], merged_pred_y, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pred = pd.merge(X_test_df['PROGRESSIVO'], pd.DataFrame(y_pred, columns=['PREDICTED']), left_index=True, right_index=True)\n",
    "merged_pred_2 = pd.merge(X_test_df['REPARTO'], merged_pred, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pred_train = pd.merge(X_train_df['PROGRESSIVO'], pd.DataFrame(np.asanyarray(y_train), columns=['LABEL']), left_index=True, right_index=True)\n",
    "merged_pred_train_2 = pd.merge(X_train_df['REPARTO'], merged_pred_train, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of durations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(merged_pred_y_2['LABEL'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of the duration of the interventions TEST', fontsize=16)\n",
    "plt.xlabel('Duration (minutes)', fontsize=14)\n",
    "plt.ylabel('Frequence', fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of durations\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(merged_pred_y_2['LABEL'], vert=False, patch_artist=True, \n",
    "            boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "            whiskerprops=dict(color='blue'), capprops=dict(color='blue'),\n",
    "            medianprops=dict(color='red'))\n",
    "plt.title('Boxplot of the duration of the interventions TEST', fontsize=16)\n",
    "plt.xlabel('Duration (minutes)', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram of durations\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(merged_pred_train['LABEL'], bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of the duration of the interventions TRAIN', fontsize=16)\n",
    "plt.xlabel('Duration (minutes)', fontsize=14)\n",
    "plt.ylabel('Frequence', fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot of durations\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(merged_pred_train['LABEL'], vert=False, patch_artist=True, \n",
    "            boxprops=dict(facecolor='lightblue', color='blue'),\n",
    "            whiskerprops=dict(color='blue'), capprops=dict(color='blue'),\n",
    "            medianprops=dict(color='red'))\n",
    "plt.title('Boxplot of the duration of the interventions TRAIN', fontsize=16)\n",
    "plt.xlabel('Duration (minutes)', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to lists for plotting\n",
    "model_names = list(mae_results.keys())\n",
    "mae_values = list(mae_results.values())\n",
    "rmse_values = list(rmse_results.values())\n",
    "r2_values = list(r2_results.values())\n",
    "\n",
    "# Create the graph of MAE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(model_names, mae_values, color='skyblue')\n",
    "plt.xlabel('MAE (minutes)')\n",
    "plt.title('Mean Absolute Error per Modello')\n",
    "plt.savefig(output_dir+'/MAE.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Create the graph of RMSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(model_names, rmse_values, color='lightgreen')\n",
    "plt.xlabel('RMSE (minutes)')\n",
    "plt.title('Root Mean Squared Error per Modello')\n",
    "plt.savefig(output_dir+'/RMSE.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Create the graph of RMSE\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(model_names, r2_values, color='gray')\n",
    "plt.xlabel('R2 (minutes)')\n",
    "plt.title('Coefficient of Determination (R² Score) per Modello')\n",
    "plt.savefig(output_dir+'/R2.png', dpi=300)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataframe with these columns: PROGRESSIVO  Pred\tGround Truth (DURATA)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\"PROGRESSIVO \":prog_test.values,\"Pred\": y_pred, \"Ground Truth\": y_test})\n",
    "\n",
    "# Save to an Excel file\n",
    "df.to_excel(output_dir+'/output.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventi, id_predictions, y_rep = merged_pred_2, merged_pred_2['PROGRESSIVO'], merged_pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_hospital(interventi, id_predictions, y_pred):\n",
    "    # Merge predicted labels into the interventi dataframe based on PROGRESSIVO\n",
    "    interventi_merged = interventi.merge(y_pred, on=\"PROGRESSIVO\", how=\"inner\")\n",
    "\n",
    "    sanremo_df = pd.DataFrame()\n",
    "    imperia_df = pd.DataFrame()\n",
    "    bordighera_df = pd.DataFrame()\n",
    "\n",
    "    for id in id_predictions:\n",
    "        row = interventi_merged.loc[interventi_merged[\"PROGRESSIVO\"] == id]\n",
    "        if row.empty:\n",
    "            continue\n",
    "\n",
    "        reparto = row[\"REPARTO\"].values[0]\n",
    "\n",
    "        if \"SANREMO\" in reparto:\n",
    "            sanremo_df = pd.concat([sanremo_df, row])\n",
    "        elif \"IMPERIA\" in reparto:\n",
    "            imperia_df = pd.concat([imperia_df, row])\n",
    "        elif \"BORDIGHERA\" in reparto:\n",
    "            bordighera_df = pd.concat([bordighera_df, row])\n",
    "\n",
    "    return sanremo_df.reset_index(drop=True), imperia_df.reset_index(drop=True), bordighera_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split prediction for each hospital to further analyses\n",
    "sanremo, imperia, bordighera = split_by_hospital(interventi, id_predictions, y_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sanremo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperia[\"ERROR\"] = imperia[\"LABEL\"] - imperia[\"PREDICTED\"]\n",
    "sanremo[\"ERROR\"] = sanremo[\"LABEL\"] - sanremo[\"PREDICTED\"]\n",
    "bordighera[\"ERROR\"] = bordighera[\"LABEL\"] - bordighera[\"PREDICTED\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imperia = imperia.sort_values(by='ERROR')\n",
    "bordighera = bordighera.sort_values(by='ERROR')\n",
    "sanremo = sanremo.sort_values(by='ERROR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['Sanremo', 'Imperia', 'Bordighera']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in name:\n",
    "    if (v == 'Sanremo'):\n",
    "        i = sanremo\n",
    "    elif(v == 'Imperia'):\n",
    "        i = imperia\n",
    "    elif(v == 'Bordighera'):\n",
    "        i = bordighera\n",
    "\n",
    "    y_pred_osp = np.asarray(i['PREDICTED'])\n",
    "    y_test_osp = np.asarray(i['LABEL'])\n",
    "    indices = list(range(len(y_test_osp)))\n",
    "\n",
    "    plt.figure(figsize=(26, 6))\n",
    "\n",
    "    # Predictions\n",
    "    plt.plot(\n",
    "        indices,\n",
    "        y_pred_osp,\n",
    "        label='Predictions',\n",
    "        color='blue',\n",
    "        linewidth=1.5,\n",
    "        marker='o',\n",
    "        markersize=5,\n",
    "        alpha=0.6,\n",
    "        zorder=2\n",
    "    )\n",
    "\n",
    "    # Real Value\n",
    "    plt.plot(\n",
    "        indices,\n",
    "        y_test_osp,\n",
    "        label='Real Value',\n",
    "        color='brown',\n",
    "        linewidth=1.5,\n",
    "        marker='x',\n",
    "        markersize=5,\n",
    "        alpha=0.6,\n",
    "        zorder=3\n",
    "    )\n",
    "\n",
    "    plt.title('Comparison between Actual and Predicted Values in '+str(v)+' (Patients sorted by error)', fontsize=20)\n",
    "    plt.xlabel('Index', fontsize=14)\n",
    "    plt.ylabel('Value', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir+'/Comparison between Actual and Predicted Values in '+str(v)+' (Patients sorted by error.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(26, 6))\n",
    "\n",
    "    # Predictions vs real value\n",
    "    plt.plot(\n",
    "        indices,\n",
    "        y_test_osp - y_pred_osp,\n",
    "        label='y_test-y_pred',\n",
    "        color='blue',\n",
    "        linewidth=1.5,\n",
    "        marker='o',\n",
    "        markersize=5,\n",
    "        alpha=0.6,\n",
    "        zorder=2\n",
    "    )\n",
    "\n",
    "\n",
    "    plt.title('Difference between Actual and Predicted Values in '+str(v)+' (Patients sorted by error)', fontsize=20)\n",
    "    plt.xlabel('Index', fontsize=14)\n",
    "    plt.ylabel('Value', fontsize=14)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir+'/Difference between Actual and Predicted Values in '+str(v)+' (Patients sorted by error.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # groupby error for each department\n",
    "    grouped = i.groupby('REPARTO')['ERROR'].apply(list)\n",
    "\n",
    "    # Boxplot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.boxplot(grouped.values, labels=grouped.index, vert=True)\n",
    "    plt.title(\"Error Distribution by Department in \"+str(v))\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir+'/Error Distribution by Department in '+str(v)+'.png', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df_shap = pd.DataFrame(X_test_scaled, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the TreeExplainer\n",
    "explainer = shap.Explainer(best_model.predict, X_test_df_shap)\n",
    "\n",
    "# Calculate SHAP values for the test set (or any data)\n",
    "shap_values = explainer(X_test_df_shap)\n",
    "shap.summary_plot(shap_values, X_test_df_shap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "radiomics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
